{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pp6KAX1UXqaK"
   },
   "source": [
    "# Question B4 (10 marks)\n",
    "\n",
    "Model degradation is a common issue faced when deploying machine learning models (including neural networks) in the real world. New data points could exhibit a different pattern from older data points due to factors such as changes in government policy or market sentiments. For instance, housing prices in Singapore have been increasing and the Singapore government has introduced 3 rounds of cooling measures over the past years (16 December 2021, 30 September 2022, 27 April 2023).\n",
    "\n",
    "In such situations, the distribution of the new data points could differ from the original data distribution which the models were trained on. Recall that machine learning models often work with the assumption that the test distribution should be similar to train distribution. When this assumption is violated, model performance will be adversely impacted.  In the last part of this assignment, we will investigate to what extent model degradation has occurred.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WsfKoCAMj9uo"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rjdf67uIarDX"
   },
   "source": [
    "Your co-investigators used a linear regression model to rapidly test out several combinations of train/test splits and shared with you their findings in a brief report attached in Appendix A below. You wish to investigate whether your deep learning model corroborates with their findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "M3-BW2LW4Icq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: alibi-detect in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (0.12.0)\n",
      "Requirement already satisfied: scikit-learn<2.0.0,>=0.20.2 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from alibi-detect) (1.5.2)\n",
      "Requirement already satisfied: scikit-image<0.23,>=0.19 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from alibi-detect) (0.22.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.0.0 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from alibi-detect) (4.45.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=1.8.0 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from alibi-detect) (2.9.2)\n",
      "Requirement already satisfied: pandas<3.0.0,>=1.0.0 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from alibi-detect) (2.2.3)\n",
      "Requirement already satisfied: catalogue<3.0.0,>=2.0.0 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from alibi-detect) (2.0.10)\n",
      "Requirement already satisfied: Pillow<11.0.0,>=5.4.1 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from alibi-detect) (10.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.28.1 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from alibi-detect) (4.66.5)\n",
      "Requirement already satisfied: dill<0.4.0,>=0.3.0 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from alibi-detect) (0.3.9)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.16.2 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from alibi-detect) (1.26.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.21.0 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from alibi-detect) (2.32.3)\n",
      "Requirement already satisfied: numba!=0.54.0,<0.60.0,>=0.50.0 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from alibi-detect) (0.59.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from alibi-detect) (4.12.2)\n",
      "Requirement already satisfied: scipy<2.0.0,>=1.3.0 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from alibi-detect) (1.12.0)\n",
      "Requirement already satisfied: opencv-python<5.0.0,>=3.2.0 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from alibi-detect) (4.10.0.84)\n",
      "Requirement already satisfied: toml<1.0.0,>=0.10.1 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from alibi-detect) (0.10.2)\n",
      "Requirement already satisfied: matplotlib<4.0.0,>=3.0.0 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from alibi-detect) (3.9.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from scikit-learn<2.0.0,>=0.20.2->alibi-detect) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from scikit-learn<2.0.0,>=0.20.2->alibi-detect) (3.5.0)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from scikit-image<0.23,>=0.19->alibi-detect) (0.4)\n",
      "Requirement already satisfied: imageio>=2.27 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from scikit-image<0.23,>=0.19->alibi-detect) (2.35.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from scikit-image<0.23,>=0.19->alibi-detect) (2024.8.30)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from scikit-image<0.23,>=0.19->alibi-detect) (3.2.1)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from scikit-image<0.23,>=0.19->alibi-detect) (24.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (0.20.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (0.25.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (0.4.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from transformers<5.0.0,>=4.0.0->alibi-detect) (6.0.2)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from pydantic<3.0.0,>=1.8.0->alibi-detect) (2.23.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from pydantic<3.0.0,>=1.8.0->alibi-detect) (0.7.0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from pandas<3.0.0,>=1.0.0->alibi-detect) (2024.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from pandas<3.0.0,>=1.0.0->alibi-detect) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from pandas<3.0.0,>=1.0.0->alibi-detect) (2024.2)\n",
      "Requirement already satisfied: colorama; platform_system == \"Windows\" in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from tqdm<5.0.0,>=4.28.1->alibi-detect) (0.4.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from requests<3.0.0,>=2.21.0->alibi-detect) (2024.8.30)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from requests<3.0.0,>=2.21.0->alibi-detect) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from requests<3.0.0,>=2.21.0->alibi-detect) (2.2.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from requests<3.0.0,>=2.21.0->alibi-detect) (3.10)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from numba!=0.54.0,<0.60.0,>=0.50.0->alibi-detect) (0.42.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (1.4.7)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0; python_version < \"3.10\" in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (6.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (3.1.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (1.3.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from matplotlib<4.0.0,>=3.0.0->alibi-detect) (4.54.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers<5.0.0,>=4.0.0->alibi-detect) (2024.9.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=1.0.0->alibi-detect) (1.16.0)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\lib\\site-packages (from importlib-resources>=3.2.0; python_version < \"3.10\"->matplotlib<4.0.0,>=3.0.0->alibi-detect) (3.20.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.3; however, version 24.2 is available.\n",
      "You should consider upgrading via the 'c:\\users\\joann\\coding projects\\ipynb dump\\ipynb-dump\\scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install alibi-detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "E7dD3Ihi4GF9"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "import os\n",
    "\n",
    "import random\n",
    "random.seed(SEED)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from alibi_detect.cd import TabularDrift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJjXNMOqcHVJ"
   },
   "source": [
    "1.Evaluate your model from B1 on data from year 2022 and report the test R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "fOUcXL5OXASY"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joann\\Coding Projects\\ipynb dump\\ipynb-dump\\lib\\site-packages\\lightning_fabric\\utilities\\cloud_io.py:56: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:55:52</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">527</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">165</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m10\u001b[0m-\u001b[1;36m01\u001b[0m \u001b[1;92m10:55:52\u001b[0m,\u001b[1;36m527\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m165\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:55:52</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">547</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">340</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m10\u001b[0m-\u001b[1;36m01\u001b[0m \u001b[1;92m10:55:52\u001b[0m,\u001b[1;36m547\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m340\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\joann\\Coding Projects\\ipynb dump\\ipynb-dump\\lib\\site-packages\\pytorch_tabular\\categorical_encoders.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "c:\\Users\\joann\\Coding Projects\\ipynb dump\\ipynb-dump\\lib\\site-packages\\pytorch_tabular\\categorical_encoders.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "c:\\Users\\joann\\Coding Projects\\ipynb dump\\ipynb-dump\\lib\\site-packages\\pytorch_tabular\\categorical_encoders.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "c:\\Users\\joann\\Coding Projects\\ipynb dump\\ipynb-dump\\lib\\site-packages\\pytorch_tabular\\categorical_encoders.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R2 for year 2022: 0.4178136950647571\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from pytorch_tabular import TabularModel\n",
    "\n",
    "df = pd.read_csv('hdb_price_prediction.csv')\n",
    "\n",
    "model = TabularModel.load_model('saved_model/model_B1')\n",
    "\n",
    "test_df_22 = df[df['year'] == 2022]\n",
    "test_predictions_22 = model.predict(test_df_22)\n",
    "\n",
    "y_true = test_df_22['resale_price']\n",
    "y_pred = test_predictions_22\n",
    "\n",
    "r2_22 = r2_score(y_true, y_pred)\n",
    "print(f'Test R2 for year 2022: {r2_22}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gsbs0iMiaUy-"
   },
   "source": [
    "2.Evaluate your model from B1 on data from year 2023 and report the test R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "B4FLRQfBaRS-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joann\\Coding Projects\\ipynb dump\\ipynb-dump\\lib\\site-packages\\lightning_fabric\\utilities\\cloud_io.py:56: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:55:53</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">014</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">165</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m10\u001b[0m-\u001b[1;36m01\u001b[0m \u001b[1;92m10:55:53\u001b[0m,\u001b[1;36m014\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m165\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:55:53</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">026</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">340</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m10\u001b[0m-\u001b[1;36m01\u001b[0m \u001b[1;92m10:55:53\u001b[0m,\u001b[1;36m026\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m340\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "c:\\Users\\joann\\Coding Projects\\ipynb dump\\ipynb-dump\\lib\\site-packages\\pytorch_tabular\\categorical_encoders.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "c:\\Users\\joann\\Coding Projects\\ipynb dump\\ipynb-dump\\lib\\site-packages\\pytorch_tabular\\categorical_encoders.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "c:\\Users\\joann\\Coding Projects\\ipynb dump\\ipynb-dump\\lib\\site-packages\\pytorch_tabular\\categorical_encoders.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n",
      "c:\\Users\\joann\\Coding Projects\\ipynb dump\\ipynb-dump\\lib\\site-packages\\pytorch_tabular\\categorical_encoders.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_encoded[col].fillna(self._imputed, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R2 for year 2023: 0.13473514277102083\n"
     ]
    }
   ],
   "source": [
    "model = TabularModel.load_model('saved_model/model_B1')\n",
    "\n",
    "\n",
    "test_df_23 = df[df['year'] == 2023]\n",
    "test_predictions_23 = model.predict(test_df_23)\n",
    "\n",
    "y_true = test_df_23['resale_price']\n",
    "y_pred = test_predictions_23\n",
    "\n",
    "r2_23 = r2_score(y_true, y_pred)\n",
    "print(f'Test R2 for year 2023: {r2_23}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11mU8sxcaSAP"
   },
   "source": [
    "3.Did model degradation occur for the deep learning model?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nviGacm6aSlf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Model Degradation in Machine Learning\\n\\n**Model degradation** refers to the decline in a model's performance when it encounters new data that does not align with the distribution of the original training data. This decline becomes more evident when the new data significantly diverges from the patterns observed during training.\\n\\n### Drop in R² Score\\n\\n- 2022 R² score: **0.418**\\n- 2023 R² score: **0.135**\\n\\nThe **R² score**, which reflects the proportion of variance in the dependent variable that can be explained by the independent variables, has **decreased notably**, indicating:\\n\\n- A **significant reduction** in the model's predictive accuracy\\n- A **reduction in the ability to generalize** to new data over time\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR ANSWER HERE\n",
    "\"\"\"\n",
    "# Model Degradation in Machine Learning\n",
    "\n",
    "**Model degradation** refers to the decline in a model's performance when it encounters new data that does not align with the distribution of the original training data. This decline becomes more evident when the new data significantly diverges from the patterns observed during training.\n",
    "\n",
    "### Drop in R² Score\n",
    "\n",
    "- 2022 R² score: **0.418**\n",
    "- 2023 R² score: **0.135**\n",
    "\n",
    "The **R² score**, which reflects the proportion of variance in the dependent variable that can be explained by the independent variables, has **decreased notably**, indicating:\n",
    "\n",
    "- A **significant reduction** in the model's predictive accuracy\n",
    "- A **reduction in the ability to generalize** to new data over time\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Degradation in Machine Learning\n",
    "\n",
    "**Model degradation** refers to the decline in a model's performance when it encounters new data that does not align with the distribution of the original training data. This decline becomes more evident when the new data significantly diverges from the patterns observed during training.\n",
    "\n",
    "### Drop in R² Score\n",
    "\n",
    "- 2022 R² score: **0.418**\n",
    "- 2023 R² score: **0.135**\n",
    "\n",
    "The **R² score**, which reflects the proportion of variance in the dependent variable that can be explained by the independent variables, has **decreased notably**, indicating:\n",
    "\n",
    "- A **significant reduction** in the model's predictive accuracy\n",
    "- A **reduction in the ability to generalize** to new data over time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KyiP8gBAcABD"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruldtSTDcYzt"
   },
   "source": [
    "4.Model degradation could be caused by [various data distribution shifts](https://huyenchip.com/2022/02/07/data-distribution-shifts-and-monitoring.html#data-shift-types): covariate shift (features), label shift and/or concept drift (altered relationship between features and labels).\n",
    "There are various conflicting terminologies in the [literature](https://www.sciencedirect.com/science/article/pii/S0950705122002854#tbl1). Let’s stick to this reference for this assignment.\n",
    "\n",
    "> Using the **Alibi Detect** library, apply the **TabularDrift** function with the training data (year 2019 and before) used as the reference and **detect which features have drifted** in the 2023 test dataset. Before running the statistical tests, ensure you **sample 1000 data points** each from the train and test data. Do not use the whole train/test data. (Hint: use this example as a guide https://docs.seldon.io/projects/alibi-detect/en/stable/examples/cd_chi2ks_adult.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "nGbdZc3ocYbB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drift? Yes!\n",
      "Threshold: 0.005\n",
      "month                \t Drift? Yes! \t Chi2     430.336 \t p-value 0.000\n",
      "town                 \t Drift? No! \t Chi2     33.178 \t p-value 0.127\n",
      "flat_model_type      \t Drift? Yes! \t Chi2     62.122 \t p-value 0.001\n",
      "storey_range         \t Drift? Yes! \t Chi2     27.842 \t p-value 0.010\n",
      "dist_to_nearest_stn  \t Drift? No! \t K-S      0.035 \t p-value 0.561\n",
      "dist_to_dhoby        \t Drift? No! \t K-S      0.059 \t p-value 0.059\n",
      "degree_centrality    \t Drift? No! \t K-S      0.038 \t p-value 0.455\n",
      "eigenvector_centrality \t Drift? No! \t K-S      0.056 \t p-value 0.084\n",
      "remaining_lease_years \t Drift? Yes! \t K-S      0.163 \t p-value 0.000\n",
      "floor_area_sqm       \t Drift? Yes! \t K-S      0.062 \t p-value 0.041\n"
     ]
    }
   ],
   "source": [
    "#TODO: Check res sma orng lain\n",
    "\n",
    "categorical_cols = ['month', 'town', 'flat_model_type', 'storey_range']  \n",
    "continuous_cols = ['dist_to_nearest_stn', 'dist_to_dhoby', 'degree_centrality', 'eigenvector_centrality', 'remaining_lease_years', 'floor_area_sqm'] \n",
    "\n",
    "# Get a random sample of the train and test datasets (1000 data points), if not randomly sampled, the p-value \n",
    "df_train = df[df['year'] <= 2019]\n",
    "df_test  = df[df['year'] == 2023]\n",
    "\n",
    "X_train_sample = df_train.sample(1000, random_state=SEED)\n",
    "X_test_sample = df_test.sample(1000, random_state=SEED)\n",
    "\n",
    "# Define the reference + test variables\n",
    "X_ref = X_train_sample[categorical_cols + continuous_cols].values\n",
    "y_ref = X_train_sample['resale_price'].values\n",
    "\n",
    "X_test = X_test_sample[categorical_cols + continuous_cols].values\n",
    "y_test = X_test_sample['resale_price'].values\n",
    "\n",
    "# Create category_map\n",
    "X = df[categorical_cols + continuous_cols]\n",
    "\n",
    "cat_map = {}\n",
    "for i in range(len(X.columns)):\n",
    "    if X.columns[i] in categorical_cols:\n",
    "        cat_map[i] = df[X.columns[i]].unique().tolist()\n",
    "categories_per_feature = {f: None for f in list(cat_map.keys())}\n",
    "\n",
    "# Initialize the TabularDrift detector with a p-value threshold\n",
    "cd = TabularDrift(X_ref, p_val=.05, categories_per_feature=categories_per_feature)\n",
    "\n",
    "# Predict drift on the test dataset\n",
    "pred = cd.predict(X_test)\n",
    "labels = ['No!', 'Yes!']\n",
    "print('Drift? {}'.format(labels[pred['data']['is_drift']]))\n",
    "print(\"Threshold:\", pred['data']['threshold'])\n",
    "\n",
    "# Detect and print drifted features\n",
    "feature_predict = cd.predict(X_test, drift_type='feature')\n",
    "\n",
    "for feature in range(cd.n_features):\n",
    "    stat = 'Chi2' if feature in list(categories_per_feature.keys()) else 'K-S'\n",
    "    fname = X.columns.values[feature]\n",
    "    is_drift = feature_predict['data']['is_drift'][feature]\n",
    "    stat_val, p_val = feature_predict['data']['distance'][feature], feature_predict['data']['p_val'][feature]\n",
    "    print(f'{fname:<20} \\t Drift? {labels[is_drift]} \\t {stat:<8} {stat_val:.3f} \\t p-value {p_val:.3f}')\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xmj3qq3PkJUf"
   },
   "source": [
    "5.Assuming that the flurry of housing measures have made an impact on the relationship between all the features and resale_price (i.e. P(Y|X) changes), which type of data distribution shift possibly led to model degradation?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5UOsX4JqkZ9S"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\n**Concept drift** occurs when the relationship between the features, **P(Y|X)** (e.g., location and flat type). This happens even though the **feature distribution (P(X))** remains relatively unchanged.\\n\\n- The **input features** (e.g., location, flat type) have not changed.\\n- We are likely unable to predict resale prices accurately due to **external factors**, such as:\\n  - New housing policies\\n  - Changes in market dynamics\\n  - Other unobserved influences\\n\\n### Distinguishing Concept Drift from Data Drift:\\n- **Data drift** involves changes in the feature distribution (**P(X)**).\\n- In contrast, **concept drift** refers to shifts in the underlying relationship between the features and the target variable (**P(Y|X)**).\\n\\nIn this instance, **concept drift** is the probable cause of the **model degradation** we're observing, as external factors have likely altered the dynamics between input features and resale prices.\\n\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR ANSWER HERE\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "**Concept drift** occurs when the relationship between the features, **P(Y|X)** (e.g., location and flat type). This happens even though the **feature distribution (P(X))** remains relatively unchanged.\n",
    "\n",
    "- The **input features** (e.g., location, flat type) have not changed.\n",
    "- We are likely unable to predict resale prices accurately due to **external factors**, such as:\n",
    "  - New housing policies\n",
    "  - Changes in market dynamics\n",
    "  - Other unobserved influences\n",
    "\n",
    "### Distinguishing Concept Drift from Data Drift:\n",
    "- **Data drift** involves changes in the feature distribution (**P(X)**).\n",
    "- In contrast, **concept drift** refers to shifts in the underlying relationship between the features and the target variable (**P(Y|X)**).\n",
    "\n",
    "In this instance, **concept drift** is the probable cause of the **model degradation** we're observing, as external factors have likely altered the dynamics between input features and resale prices.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Concept drift** occurs when the relationship between the features, **P(Y|X)** (e.g., location and flat type). This happens even though the **feature distribution (P(X))** remains relatively unchanged.\n",
    "\n",
    "- The **input features** (e.g., location, flat type) have not changed.\n",
    "- We are likely unable to predict resale prices accurately due to **external factors**, such as:\n",
    "  - New housing policies\n",
    "  - Changes in market dynamics\n",
    "  - Other unobserved influences\n",
    "\n",
    "### Distinguishing Concept Drift from Data Drift:\n",
    "- **Data drift** involves changes in the feature distribution (**P(X)**).\n",
    "- In contrast, **concept drift** refers to shifts in the underlying relationship between the features and the target variable (**P(Y|X)**).\n",
    "\n",
    "In this instance, **concept drift** is the probable cause of the **model degradation** we're observing, as external factors have likely altered the dynamics between input features and resale prices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DM2OoOJdkZj1"
   },
   "source": [
    "6.From your analysis via TabularDrift, which features contribute to this shift?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "V3licBjskdLL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nBased on our results, the following features demonstrate **significant drift** (p-value < 0.05):\\n\\n- Month\\n- Flat Model Type\\n- Storey Range\\n- Remaining Lease Years\\n- Floor Area (sqm)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# YOUR ANSWER HERE\n",
    "\"\"\"\n",
    "Based on our results, the following features demonstrate **significant drift** (p-value < 0.05):\n",
    "\n",
    "- Month\n",
    "- Flat Model Type\n",
    "- Storey Range\n",
    "- Remaining Lease Years\n",
    "- Floor Area (sqm)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on our results, the following features demonstrate **significant drift** (p-value < 0.05):\n",
    "\n",
    "- Month\n",
    "- Flat Model Type\n",
    "- Storey Range\n",
    "- Remaining Lease Years\n",
    "- Floor Area (sqm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yB3fSvKskhEJ"
   },
   "source": [
    "7.Suggest 1 way to address model degradation and implement it, showing improved test R2 for year 2023.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "EqFinZObcYXu"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:55:53</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">566</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">140</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m10\u001b[0m-\u001b[1;36m01\u001b[0m \u001b[1;92m10:55:53\u001b[0m,\u001b[1;36m566\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m140\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:55:53</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">600</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">524</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m10\u001b[0m-\u001b[1;36m01\u001b[0m \u001b[1;92m10:55:53\u001b[0m,\u001b[1;36m600\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m524\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:55:53</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">629</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:499</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m10\u001b[0m-\u001b[1;36m01\u001b[0m \u001b[1;92m10:55:53\u001b[0m,\u001b[1;36m629\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:499\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:55:53</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">718</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">574</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: CategoryEmbeddingModel \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m10\u001b[0m-\u001b[1;36m01\u001b[0m \u001b[1;92m10:55:53\u001b[0m,\u001b[1;36m718\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m574\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: CategoryEmbeddingModel \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:55:53</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">751</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">340</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m10\u001b[0m-\u001b[1;36m01\u001b[0m \u001b[1;92m10:55:53\u001b[0m,\u001b[1;36m751\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m340\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:55:53</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">834</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">630</span><span style=\"font-weight: bold\">}</span> - INFO - Auto LR Find Started                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m10\u001b[0m-\u001b[1;36m01\u001b[0m \u001b[1;92m10:55:53\u001b[0m,\u001b[1;36m834\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m630\u001b[0m\u001b[1m}\u001b[0m - INFO - Auto LR Find Started                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8612909b3b69420f8a9fe4194ee2c83f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.5754399373371567\n",
      "Restoring states from the checkpoint path at c:\\Users\\joann\\Coding Projects\\ipynb dump\\.lr_find_7a0905fe-ac28-4104-bd79-c5ec13892a9c.ckpt\n",
      "Restored all states from the checkpoint at c:\\Users\\joann\\Coding Projects\\ipynb dump\\.lr_find_7a0905fe-ac28-4104-bd79-c5ec13892a9c.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:55:57</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">978</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">643</span><span style=\"font-weight: bold\">}</span> - INFO - Suggested LR: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5754399373371567</span>. For plot  \n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m10\u001b[0m-\u001b[1;36m01\u001b[0m \u001b[1;92m10:55:57\u001b[0m,\u001b[1;36m978\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m643\u001b[0m\u001b[1m}\u001b[0m - INFO - Suggested LR: \u001b[1;36m0.5754399373371567\u001b[0m. For plot  \n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:55:57</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">982</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">652</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m10\u001b[0m-\u001b[1;36m01\u001b[0m \u001b[1;92m10:55:57\u001b[0m,\u001b[1;36m982\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m652\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ CategoryEmbeddingBackbone │  3.0 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer          │  1.7 K │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ head             │ LinearHead                │     51 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss                   │      0 │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ CategoryEmbeddingBackbone │  3.0 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer          │  1.7 K │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ head             │ LinearHead                │     51 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss                   │      0 │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 4.7 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 4.7 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 4.7 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 4.7 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58400453fc9a4fdbb4f934e3dc76f4e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:56:19</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">387</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">663</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m10\u001b[0m-\u001b[1;36m01\u001b[0m \u001b[1;92m10:56:19\u001b[0m,\u001b[1;36m387\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m663\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">01</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">10:56:19</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">388</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1489</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2024\u001b[0m-\u001b[1;36m10\u001b[0m-\u001b[1;36m01\u001b[0m \u001b[1;92m10:56:19\u001b[0m,\u001b[1;36m388\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1489\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9da87fc18794d5483c97e4e280c4be0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       17107908608.0       </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test_mean_squared_error  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       17107908608.0       </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      17107908608.0      \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test_mean_squared_error \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      17107908608.0      \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model on the new training data\n",
    "\n",
    "import warnings\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig\n",
    "from pytorch_tabular.config import (\n",
    "    DataConfig,\n",
    "    OptimizerConfig,\n",
    "    TrainerConfig,\n",
    ")\n",
    "\n",
    "# Define the DataConfig\n",
    "data_config = DataConfig(\n",
    "    target=['resale_price'], \n",
    "    continuous_cols=['dist_to_nearest_stn', 'dist_to_dhoby', 'degree_centrality', 'eigenvector_centrality', 'remaining_lease_years', 'floor_area_sqm'],\n",
    "    categorical_cols=['month', 'town', 'flat_model_type', 'storey_range']\n",
    ")\n",
    "\n",
    "# Define the TrainerConfig\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=True,  \n",
    "    batch_size=1024,  \n",
    "    max_epochs=50  \n",
    ")\n",
    "\n",
    "# Define the CategoryEmbeddingModelConfig\n",
    "model_config = CategoryEmbeddingModelConfig(\n",
    "    task=\"regression\", \n",
    "    layers=\"50\",  \n",
    ")\n",
    "\n",
    "# Define the OptimizerConfig\n",
    "optimizer_config = OptimizerConfig(\n",
    "    optimizer=\"Adam\"  \n",
    ")\n",
    "\n",
    "# Define the TabularModel\n",
    "model_new = TabularModel(\n",
    "    data_config=data_config,  \n",
    "    model_config=model_config,  \n",
    "    optimizer_config=optimizer_config, \n",
    "    trainer_config=trainer_config\n",
    ")\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df_2019 = df[df['year'] <= 2019]\n",
    "df_2022 = df[df['year'] == 2022]\n",
    "df_test  = df[df['year'] == 2023]\n",
    "\n",
    "# Split the 2022 data in half for train and validation\n",
    "df_2022_first_half = df_2022.iloc[:len(df_2022)//2]\n",
    "df_2022_second_half = df_2022.iloc[len(df_2022)//2:]\n",
    "\n",
    "df_train = pd.concat([df_2019, df_2022_first_half])\n",
    "df_val = df_2022_second_half\n",
    "\n",
    "model_new.fit(train=df_train, validation=df_val, seed=SEED)\n",
    "pred_new = model_new.predict(df_test)\n",
    "res_new = model_new.evaluate(df_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 130797.2002051138\n",
      "Test R2: 0.41969714032253713\n"
     ]
    }
   ],
   "source": [
    "#TODO: Check res orng lain gmna\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import math\n",
    "\n",
    "y_true = df_test['resale_price']  \n",
    "y_pred = pred_new['resale_price_prediction']  \n",
    "\n",
    "rmse = mean_squared_error(y_true, y_pred, squared=False) \n",
    "r2 = r2_score(y_true, y_pred)\n",
    "\n",
    "print(f'Test RMSE: {rmse}')\n",
    "print(f'Test R2: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addressing Concept Drift in Model Degradation\n",
    "\n",
    "As we have identified **concept drift** as the main cause of model degradation, we can address it by retraining the model on new data (the year 2022). This will help the model learn the new relationships between the features and the target variable.\n",
    "\n",
    "By doing do, we have improved the model's R2 score from 0.135 to 0.420\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQG9hZvAaq5g"
   },
   "source": [
    "### Appendix A\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_ARi2OxbDuZ"
   },
   "source": [
    "Here are our results from a linear regression model. We used StandardScaler for continuous variables and OneHotEncoder for categorical variables.\n",
    "\n",
    "While 2021 data can be predicted well, test R2 dropped rapidly for 2022 and 2023.\n",
    "\n",
    "| Training set | Test set | Test R2 |\n",
    "|--------------|----------|---------|\n",
    "| Year <= 2020 | 2021     | 0.76    |\n",
    "| Year <= 2020 | **2022**     | 0.41    |\n",
    "| Year <= 2020 | **2023**     | **0.10**   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmv91FqgbI8h"
   },
   "source": [
    "Similarly, a model trained on 2017 data can predict 2018-2021 well (with slight degradation in performance for 2021), but drops drastically in 2022 and 2023.\n",
    "\n",
    "| Training set | Test set | Test R2 |\n",
    "|--------------|----------|---------|\n",
    "| 2017         | 2018     | 0.90    |\n",
    "|              | 2019     | 0.89    |\n",
    "|              | 2020     | 0.87    |\n",
    "|              | 2021     | 0.72    |\n",
    "|              | **2022**     | **0.37**    |\n",
    "|              | **2023**     | **0.09**    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ayKGs106bI6S"
   },
   "source": [
    "With the test set fixed at year 2021, training on data from 2017-2020 still works well on the test data, with minimal degradation. Training sets closer to year 2021 generally do better.\n",
    "\n",
    "| Training set | Test set | Test R2 |\n",
    "|--------------|----------|---------|\n",
    "| 2020         | 2021     | 0.81    |\n",
    "| 2019         | 2021     | 0.75    |\n",
    "| 2018         | 2021     | 0.73    |\n",
    "| 2017         | 2021     | 0.72    |"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNWUKTcEICJ0j/YcXkGkr53",
   "collapsed_sections": [
    "wQG9hZvAaq5g"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ipynb-dump",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
