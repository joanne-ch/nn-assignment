{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question A2 (10 marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this question, we will determine the optimal batch size for mini-batch gradient descent. Find the optimal batch size for mini-batch gradient descent by training the neural network and evaluating the performances for different batch sizes. Note: Use 5-fold cross-validation on the training partition to perform hyperparameter selection. You will have to reconsider the scaling of the dataset during the 5-fold cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot mean cross-validation accuracies on the final epoch for different batch sizes as a scatter plot. Limit search space to batch sizes {64, 128, 256, 512}. Next, create a table of time taken to train the network on the last epoch against different batch sizes. Finally, select the optimal batch size and state a reason for your selection.\n",
    "\n",
    "\n",
    "This might take a while to run, so plan your time carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from scipy.io import wavfile as wav\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "from common_utils import set_seed\n",
    "\n",
    "# setting seed\n",
    "set_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.To reduce repeated code, place your\n",
    "\n",
    "- network (MLP defined in QA1)\n",
    "\n",
    "- torch datasets (CustomDataset defined in QA1)\n",
    "- loss function (loss_fn defined in QA1)\n",
    "in a separate file called common_utils.py\n",
    "\n",
    "Import them into this file. You will not be repenalised for any error in QA1 here as the code in QA1 will not be remarked.\n",
    "\n",
    "The following code cell will not be marked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common_utils import MLP, split_dataset, preprocess_dataset\n",
    "\n",
    "df = pd.read_csv('simplified.csv')\n",
    "df['label'] = df['filename'].str.split('_').str[-2]\n",
    "df['label'].value_counts()\n",
    "\n",
    "X_train, y_train, X_test, y_test = split_dataset(df, [\"filename\", \"label\"], 0.2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.Define different folds for different batch sizes to get a dictionary of training and validation datasets. Preprocess your datasets accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def generate_cv_folds_for_batch_sizes(parameters, X_train, y_train):\n",
    "    \"\"\"\n",
    "    returns:\n",
    "    X_train_scaled_dict(dict) where X_train_scaled_dict[batch_size] is a list of the preprocessed training matrix for the different folds.\n",
    "    X_val_scaled_dict(dict) where X_val_scaled_dict[batch_size] is a list of the processed validation matrix for the different folds.\n",
    "    y_train_dict(dict) where y_train_dict[batch_size] is a list of labels for the different folds\n",
    "    y_val_dict(dict) where y_val_dict[batch_size] is a list of labels for the different folds\n",
    "    \"\"\"\n",
    "\n",
    "    X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict = {},{},{},{}\n",
    "\n",
    "    split = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "    for batch_size in parameters:\n",
    "        X_train_scaled_dict[batch_size], X_val_scaled_dict[batch_size], y_train_dict[batch_size], y_val_dict[batch_size] = [], [], [], []\n",
    "        \n",
    "        for train_idx, val_idx in split.split(X_train, y_train):\n",
    "            X_train_fold, y_train_fold = X_train[train_idx], y_train[train_idx]\n",
    "            X_val_fold, y_val_fold = X_train[val_idx], y_train[val_idx]\n",
    "\n",
    "            scaler = StandardScaler()\n",
    "            X_train_fold_scaled = scaler.fit_transform(X_train_fold)\n",
    "            X_val_fold_scaled = scaler.transform(X_val_fold)\n",
    "\n",
    "            X_train_scaled_dict[batch_size].append(X_train_fold_scaled)\n",
    "            y_train_dict[batch_size].append(y_train_fold)\n",
    "            X_val_scaled_dict[batch_size].append(X_val_fold_scaled)\n",
    "            y_val_dict[batch_size].append(y_val_fold)\n",
    "\n",
    "    return X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict\n",
    "\n",
    "batch_sizes = [64, 128, 256, 512]\n",
    "X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict = generate_cv_folds_for_batch_sizes(batch_sizes, X_train.to_numpy(), y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of train + validation set: 9645\n",
      "\n",
      "Batch Size: 64\n",
      "X_train_scaled: (7716, 77)\n",
      "X_val_scaled: (1929, 77)\n",
      "y_train: (7716,)\n",
      "y_val: (1929,)\n",
      "\n",
      "Batch Size: 128\n",
      "X_train_scaled: (7716, 77)\n",
      "X_val_scaled: (1929, 77)\n",
      "y_train: (7716,)\n",
      "y_val: (1929,)\n",
      "\n",
      "Batch Size: 256\n",
      "X_train_scaled: (7716, 77)\n",
      "X_val_scaled: (1929, 77)\n",
      "y_train: (7716,)\n",
      "y_val: (1929,)\n",
      "\n",
      "Batch Size: 512\n",
      "X_train_scaled: (7716, 77)\n",
      "X_val_scaled: (1929, 77)\n",
      "y_train: (7716,)\n",
      "y_val: (1929,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"length of train + validation set: {len(X_train)}\")\n",
    "print()\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    print(f'Batch Size: {batch_size}')\n",
    "    print(f'X_train_scaled: {X_train_scaled_dict[batch_size][0].shape}')\n",
    "    print(f'X_val_scaled: {X_val_scaled_dict[batch_size][0].shape}')\n",
    "    print(f'y_train: {y_train_dict[batch_size][0].shape}')\n",
    "    print(f'y_val: {y_val_dict[batch_size][0].shape}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.Perform hyperparameter tuning for the different batch sizes with 5-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float)\n",
    "        self.y = torch.tensor(y, dtype=torch.float).unsqueeze(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "def get_train_val_loaders_dict(X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict, batch_sizes):\n",
    "    train_loaders_dict = {}\n",
    "    val_loaders_dict = {}\n",
    "\n",
    "    for batch_size in batch_sizes:\n",
    "        train_loaders = []\n",
    "        val_loaders = []\n",
    "\n",
    "        for i in range(5):\n",
    "            train_data = CustomDataset(X_train_scaled_dict[batch_size][i], y_train_dict[batch_size][i])\n",
    "            val_data = CustomDataset(X_val_scaled_dict[batch_size][i], y_val_dict[batch_size][i])\n",
    "\n",
    "            train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "            val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "            train_loaders.append(train_dataloader)\n",
    "            val_loaders.append(val_dataloader)\n",
    "\n",
    "        train_loaders_dict[batch_size] = train_loaders\n",
    "        val_loaders_dict[batch_size] = val_loaders\n",
    "    \n",
    "    return train_loaders_dict, val_loaders_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    train_loss, train_correct = 0, 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        train_correct += torch.sum(torch.eq(pred > 0.5, y.clone().detach()))\n",
    "\n",
    "    train_loss /= num_batches\n",
    "    train_correct = train_correct.float() /size\n",
    "\n",
    "    return train_loss, train_correct\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    \n",
    "    test_loss, test_correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            test_correct += torch.sum(torch.eq(pred > 0.5, y.clone().detach()))\n",
    "        test_loss /= num_batches\n",
    "        test_correct = test_correct.float()/size\n",
    "\n",
    "    return test_loss, test_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------- Batch Size: 64 ---------------------\n",
      "------ Fold: 1 ------\n",
      "Epoch 1: Train_accuracy: 55.61%, Train_loss: 0.684294, Val_accuracy: 58.63%, val_loss: 0.668508\n",
      "Epoch 2: Train_accuracy: 58.99%, Train_loss: 0.669407, Val_accuracy: 62.16%, val_loss: 0.659328\n",
      "Epoch 3: Train_accuracy: 61.57%, Train_loss: 0.652749, Val_accuracy: 63.76%, val_loss: 0.640573\n",
      "Epoch 4: Train_accuracy: 63.13%, Train_loss: 0.638786, Val_accuracy: 63.45%, val_loss: 0.643406\n",
      "Epoch 5: Train_accuracy: 64.96%, Train_loss: 0.616807, Val_accuracy: 62.78%, val_loss: 0.639849\n",
      "Epoch 6: Train_accuracy: 66.89%, Train_loss: 0.603340, Val_accuracy: 65.63%, val_loss: 0.607886\n",
      "Epoch 7: Train_accuracy: 69.04%, Train_loss: 0.585104, Val_accuracy: 67.81%, val_loss: 0.582574\n",
      "Epoch 8: Train_accuracy: 69.89%, Train_loss: 0.568661, Val_accuracy: 68.64%, val_loss: 0.590300\n",
      "Epoch 9: Train_accuracy: 71.05%, Train_loss: 0.549875, Val_accuracy: 68.90%, val_loss: 0.589280\n",
      "Epoch 10: Train_accuracy: 72.76%, Train_loss: 0.533254, Val_accuracy: 68.90%, val_loss: 0.574926\n",
      "Epoch 11: Train_accuracy: 74.56%, Train_loss: 0.516153, Val_accuracy: 70.09%, val_loss: 0.560299\n",
      "Epoch 12: Train_accuracy: 74.95%, Train_loss: 0.502382, Val_accuracy: 71.23%, val_loss: 0.556852\n",
      "Epoch 13: Train_accuracy: 76.00%, Train_loss: 0.486603, Val_accuracy: 69.78%, val_loss: 0.585324\n",
      "Epoch 14: Train_accuracy: 77.35%, Train_loss: 0.470704, Val_accuracy: 70.24%, val_loss: 0.565332\n",
      "Epoch 15: Train_accuracy: 77.49%, Train_loss: 0.460557, Val_accuracy: 70.55%, val_loss: 0.574964\n",
      "Batch size 64, Fold 1, Epoch stopped at 15 with validation loss: 0.5750 and validation accuracy: 0.7055\n",
      "\n",
      "------ Fold: 2 ------\n",
      "Epoch 1: Train_accuracy: 56.08%, Train_loss: 0.681293, Val_accuracy: 56.82%, val_loss: 0.683093\n",
      "Epoch 2: Train_accuracy: 60.54%, Train_loss: 0.662605, Val_accuracy: 58.53%, val_loss: 0.671648\n",
      "Epoch 3: Train_accuracy: 63.13%, Train_loss: 0.642593, Val_accuracy: 59.46%, val_loss: 0.662103\n",
      "Epoch 4: Train_accuracy: 64.35%, Train_loss: 0.627411, Val_accuracy: 60.50%, val_loss: 0.662795\n",
      "Epoch 5: Train_accuracy: 66.38%, Train_loss: 0.606348, Val_accuracy: 63.56%, val_loss: 0.633793\n",
      "Epoch 6: Train_accuracy: 68.16%, Train_loss: 0.591562, Val_accuracy: 64.02%, val_loss: 0.646652\n",
      "Epoch 7: Train_accuracy: 70.19%, Train_loss: 0.563336, Val_accuracy: 65.16%, val_loss: 0.625787\n",
      "Epoch 8: Train_accuracy: 71.46%, Train_loss: 0.547940, Val_accuracy: 65.32%, val_loss: 0.627305\n",
      "Epoch 9: Train_accuracy: 72.82%, Train_loss: 0.531615, Val_accuracy: 67.24%, val_loss: 0.615242\n",
      "Epoch 10: Train_accuracy: 74.03%, Train_loss: 0.514094, Val_accuracy: 67.81%, val_loss: 0.613078\n",
      "Epoch 11: Train_accuracy: 75.82%, Train_loss: 0.495350, Val_accuracy: 67.29%, val_loss: 0.618354\n",
      "Epoch 12: Train_accuracy: 77.03%, Train_loss: 0.478399, Val_accuracy: 66.72%, val_loss: 0.615649\n",
      "Epoch 13: Train_accuracy: 76.74%, Train_loss: 0.473598, Val_accuracy: 69.15%, val_loss: 0.592847\n",
      "Epoch 14: Train_accuracy: 77.93%, Train_loss: 0.458759, Val_accuracy: 68.12%, val_loss: 0.610490\n",
      "Epoch 15: Train_accuracy: 79.56%, Train_loss: 0.437317, Val_accuracy: 68.74%, val_loss: 0.622344\n",
      "Epoch 16: Train_accuracy: 79.48%, Train_loss: 0.436657, Val_accuracy: 68.58%, val_loss: 0.621490\n",
      "Batch size 64, Fold 2, Epoch stopped at 16 with validation loss: 0.6215 and validation accuracy: 0.6858\n",
      "\n",
      "------ Fold: 3 ------\n",
      "Epoch 1: Train_accuracy: 56.12%, Train_loss: 0.682270, Val_accuracy: 58.27%, val_loss: 0.674544\n",
      "Epoch 2: Train_accuracy: 59.88%, Train_loss: 0.663973, Val_accuracy: 60.50%, val_loss: 0.666677\n",
      "Epoch 3: Train_accuracy: 62.29%, Train_loss: 0.647248, Val_accuracy: 60.86%, val_loss: 0.658476\n",
      "Epoch 4: Train_accuracy: 64.84%, Train_loss: 0.623650, Val_accuracy: 62.00%, val_loss: 0.645179\n",
      "Epoch 5: Train_accuracy: 66.93%, Train_loss: 0.607468, Val_accuracy: 60.86%, val_loss: 0.660156\n",
      "Epoch 6: Train_accuracy: 68.33%, Train_loss: 0.586797, Val_accuracy: 63.76%, val_loss: 0.644064\n",
      "Epoch 7: Train_accuracy: 69.93%, Train_loss: 0.571015, Val_accuracy: 64.49%, val_loss: 0.626746\n",
      "Epoch 8: Train_accuracy: 71.58%, Train_loss: 0.551312, Val_accuracy: 65.58%, val_loss: 0.629228\n",
      "Epoch 9: Train_accuracy: 72.58%, Train_loss: 0.533497, Val_accuracy: 65.68%, val_loss: 0.625571\n",
      "Epoch 10: Train_accuracy: 73.85%, Train_loss: 0.519794, Val_accuracy: 67.34%, val_loss: 0.619815\n",
      "Epoch 11: Train_accuracy: 74.82%, Train_loss: 0.505773, Val_accuracy: 66.04%, val_loss: 0.622395\n",
      "Epoch 12: Train_accuracy: 75.26%, Train_loss: 0.497688, Val_accuracy: 69.47%, val_loss: 0.589644\n",
      "Epoch 13: Train_accuracy: 76.44%, Train_loss: 0.480884, Val_accuracy: 67.55%, val_loss: 0.613484\n",
      "Epoch 14: Train_accuracy: 77.60%, Train_loss: 0.461317, Val_accuracy: 69.62%, val_loss: 0.596185\n",
      "Epoch 15: Train_accuracy: 78.41%, Train_loss: 0.450019, Val_accuracy: 69.10%, val_loss: 0.595992\n",
      "Batch size 64, Fold 3, Epoch stopped at 15 with validation loss: 0.5960 and validation accuracy: 0.6910\n",
      "\n",
      "------ Fold: 4 ------\n",
      "Epoch 1: Train_accuracy: 54.13%, Train_loss: 0.684727, Val_accuracy: 57.75%, val_loss: 0.679776\n",
      "Epoch 2: Train_accuracy: 59.11%, Train_loss: 0.667145, Val_accuracy: 59.82%, val_loss: 0.670081\n",
      "Epoch 3: Train_accuracy: 62.31%, Train_loss: 0.649370, Val_accuracy: 59.93%, val_loss: 0.657434\n",
      "Epoch 4: Train_accuracy: 64.54%, Train_loss: 0.628140, Val_accuracy: 61.12%, val_loss: 0.655532\n",
      "Epoch 5: Train_accuracy: 66.61%, Train_loss: 0.614046, Val_accuracy: 63.30%, val_loss: 0.634185\n",
      "Epoch 6: Train_accuracy: 67.70%, Train_loss: 0.596669, Val_accuracy: 62.78%, val_loss: 0.637212\n",
      "Epoch 7: Train_accuracy: 70.22%, Train_loss: 0.574981, Val_accuracy: 64.90%, val_loss: 0.629042\n",
      "Epoch 8: Train_accuracy: 71.22%, Train_loss: 0.556329, Val_accuracy: 66.41%, val_loss: 0.614819\n",
      "Epoch 9: Train_accuracy: 72.49%, Train_loss: 0.543931, Val_accuracy: 65.73%, val_loss: 0.614838\n",
      "Epoch 10: Train_accuracy: 73.42%, Train_loss: 0.534831, Val_accuracy: 66.98%, val_loss: 0.606851\n",
      "Epoch 11: Train_accuracy: 74.16%, Train_loss: 0.516614, Val_accuracy: 66.04%, val_loss: 0.612247\n",
      "Epoch 12: Train_accuracy: 74.84%, Train_loss: 0.503819, Val_accuracy: 68.58%, val_loss: 0.590899\n",
      "Epoch 13: Train_accuracy: 77.40%, Train_loss: 0.476540, Val_accuracy: 69.67%, val_loss: 0.609973\n",
      "Epoch 14: Train_accuracy: 77.32%, Train_loss: 0.470320, Val_accuracy: 67.70%, val_loss: 0.628600\n",
      "Epoch 15: Train_accuracy: 77.89%, Train_loss: 0.463794, Val_accuracy: 70.71%, val_loss: 0.589423\n",
      "Epoch 16: Train_accuracy: 79.30%, Train_loss: 0.444219, Val_accuracy: 70.76%, val_loss: 0.592383\n",
      "Epoch 17: Train_accuracy: 80.40%, Train_loss: 0.429336, Val_accuracy: 67.96%, val_loss: 0.630838\n",
      "Epoch 18: Train_accuracy: 79.96%, Train_loss: 0.426382, Val_accuracy: 70.35%, val_loss: 0.590486\n",
      "Batch size 64, Fold 4, Epoch stopped at 18 with validation loss: 0.5905 and validation accuracy: 0.7035\n",
      "\n",
      "------ Fold: 5 ------\n",
      "Epoch 1: Train_accuracy: 55.33%, Train_loss: 0.683717, Val_accuracy: 57.02%, val_loss: 0.678673\n",
      "Epoch 2: Train_accuracy: 59.66%, Train_loss: 0.664274, Val_accuracy: 59.98%, val_loss: 0.660699\n",
      "Epoch 3: Train_accuracy: 61.82%, Train_loss: 0.645611, Val_accuracy: 60.24%, val_loss: 0.654916\n",
      "Epoch 4: Train_accuracy: 63.83%, Train_loss: 0.629914, Val_accuracy: 61.38%, val_loss: 0.653222\n",
      "Epoch 5: Train_accuracy: 65.15%, Train_loss: 0.615091, Val_accuracy: 63.09%, val_loss: 0.642393\n",
      "Epoch 6: Train_accuracy: 67.83%, Train_loss: 0.596539, Val_accuracy: 64.07%, val_loss: 0.632802\n",
      "Epoch 7: Train_accuracy: 69.50%, Train_loss: 0.571761, Val_accuracy: 65.11%, val_loss: 0.631630\n",
      "Epoch 8: Train_accuracy: 70.87%, Train_loss: 0.561625, Val_accuracy: 65.16%, val_loss: 0.625131\n",
      "Epoch 9: Train_accuracy: 72.34%, Train_loss: 0.542525, Val_accuracy: 66.30%, val_loss: 0.618883\n",
      "Epoch 10: Train_accuracy: 73.98%, Train_loss: 0.513578, Val_accuracy: 67.19%, val_loss: 0.629877\n",
      "Epoch 11: Train_accuracy: 74.09%, Train_loss: 0.509657, Val_accuracy: 67.03%, val_loss: 0.630640\n",
      "Epoch 12: Train_accuracy: 75.96%, Train_loss: 0.489746, Val_accuracy: 67.08%, val_loss: 0.628820\n",
      "Batch size 64, Fold 5, Epoch stopped at 12 with validation loss: 0.6288 and validation accuracy: 0.6708\n",
      "\n",
      "--------------------- Batch Size: 128 ---------------------\n",
      "------ Fold: 1 ------\n",
      "Epoch 1: Train_accuracy: 54.70%, Train_loss: 0.685653, Val_accuracy: 58.84%, val_loss: 0.672208\n",
      "Epoch 2: Train_accuracy: 58.14%, Train_loss: 0.673528, Val_accuracy: 60.71%, val_loss: 0.649350\n",
      "Epoch 3: Train_accuracy: 61.29%, Train_loss: 0.653970, Val_accuracy: 63.45%, val_loss: 0.642775\n",
      "Epoch 4: Train_accuracy: 62.83%, Train_loss: 0.637273, Val_accuracy: 64.96%, val_loss: 0.622338\n",
      "Epoch 5: Train_accuracy: 64.89%, Train_loss: 0.627653, Val_accuracy: 64.23%, val_loss: 0.622975\n",
      "Epoch 6: Train_accuracy: 66.51%, Train_loss: 0.607535, Val_accuracy: 65.58%, val_loss: 0.616394\n",
      "Epoch 7: Train_accuracy: 68.56%, Train_loss: 0.589077, Val_accuracy: 66.51%, val_loss: 0.612765\n",
      "Epoch 8: Train_accuracy: 69.23%, Train_loss: 0.580379, Val_accuracy: 69.62%, val_loss: 0.571742\n",
      "Epoch 9: Train_accuracy: 71.10%, Train_loss: 0.561597, Val_accuracy: 64.59%, val_loss: 0.603844\n",
      "Epoch 10: Train_accuracy: 72.15%, Train_loss: 0.546921, Val_accuracy: 68.38%, val_loss: 0.574933\n",
      "Epoch 11: Train_accuracy: 73.61%, Train_loss: 0.527565, Val_accuracy: 67.76%, val_loss: 0.596194\n",
      "Batch size 128, Fold 1, Epoch stopped at 11 with validation loss: 0.5962 and validation accuracy: 0.6776\n",
      "\n",
      "------ Fold: 2 ------\n",
      "Epoch 1: Train_accuracy: 54.90%, Train_loss: 0.685771, Val_accuracy: 56.40%, val_loss: 0.682256\n",
      "Epoch 2: Train_accuracy: 59.25%, Train_loss: 0.667010, Val_accuracy: 58.11%, val_loss: 0.663449\n",
      "Epoch 3: Train_accuracy: 61.30%, Train_loss: 0.649923, Val_accuracy: 58.11%, val_loss: 0.677059\n",
      "Epoch 4: Train_accuracy: 63.48%, Train_loss: 0.634098, Val_accuracy: 60.81%, val_loss: 0.654240\n",
      "Epoch 5: Train_accuracy: 65.03%, Train_loss: 0.623636, Val_accuracy: 60.76%, val_loss: 0.653957\n",
      "Epoch 6: Train_accuracy: 66.93%, Train_loss: 0.607827, Val_accuracy: 64.28%, val_loss: 0.624226\n",
      "Epoch 7: Train_accuracy: 68.51%, Train_loss: 0.588037, Val_accuracy: 65.22%, val_loss: 0.634124\n",
      "Epoch 8: Train_accuracy: 69.92%, Train_loss: 0.571518, Val_accuracy: 64.18%, val_loss: 0.630127\n",
      "Epoch 9: Train_accuracy: 71.24%, Train_loss: 0.561038, Val_accuracy: 63.35%, val_loss: 0.634389\n",
      "Batch size 128, Fold 2, Epoch stopped at 9 with validation loss: 0.6344 and validation accuracy: 0.6335\n",
      "\n",
      "------ Fold: 3 ------\n",
      "Epoch 1: Train_accuracy: 54.21%, Train_loss: 0.687637, Val_accuracy: 55.83%, val_loss: 0.677578\n",
      "Epoch 2: Train_accuracy: 59.75%, Train_loss: 0.667720, Val_accuracy: 58.48%, val_loss: 0.675600\n",
      "Epoch 3: Train_accuracy: 62.21%, Train_loss: 0.646800, Val_accuracy: 61.28%, val_loss: 0.666297\n",
      "Epoch 4: Train_accuracy: 64.00%, Train_loss: 0.634017, Val_accuracy: 60.91%, val_loss: 0.660163\n",
      "Epoch 5: Train_accuracy: 66.02%, Train_loss: 0.616941, Val_accuracy: 63.40%, val_loss: 0.657207\n",
      "Epoch 6: Train_accuracy: 66.65%, Train_loss: 0.603985, Val_accuracy: 62.10%, val_loss: 0.644425\n",
      "Epoch 7: Train_accuracy: 67.79%, Train_loss: 0.590184, Val_accuracy: 62.78%, val_loss: 0.625879\n",
      "Epoch 8: Train_accuracy: 69.53%, Train_loss: 0.573527, Val_accuracy: 64.49%, val_loss: 0.631276\n",
      "Epoch 9: Train_accuracy: 71.00%, Train_loss: 0.558979, Val_accuracy: 65.01%, val_loss: 0.635421\n",
      "Epoch 10: Train_accuracy: 72.11%, Train_loss: 0.545237, Val_accuracy: 65.84%, val_loss: 0.630669\n",
      "Batch size 128, Fold 3, Epoch stopped at 10 with validation loss: 0.6307 and validation accuracy: 0.6584\n",
      "\n",
      "------ Fold: 4 ------\n",
      "Epoch 1: Train_accuracy: 55.50%, Train_loss: 0.683754, Val_accuracy: 58.89%, val_loss: 0.676797\n",
      "Epoch 2: Train_accuracy: 58.90%, Train_loss: 0.670607, Val_accuracy: 59.41%, val_loss: 0.665630\n",
      "Epoch 3: Train_accuracy: 60.87%, Train_loss: 0.655757, Val_accuracy: 60.76%, val_loss: 0.659448\n",
      "Epoch 4: Train_accuracy: 62.93%, Train_loss: 0.636449, Val_accuracy: 59.36%, val_loss: 0.667834\n",
      "Epoch 5: Train_accuracy: 65.03%, Train_loss: 0.627318, Val_accuracy: 60.71%, val_loss: 0.656298\n",
      "Epoch 6: Train_accuracy: 66.72%, Train_loss: 0.609363, Val_accuracy: 61.64%, val_loss: 0.657484\n",
      "Epoch 7: Train_accuracy: 68.74%, Train_loss: 0.586574, Val_accuracy: 62.93%, val_loss: 0.653891\n",
      "Epoch 8: Train_accuracy: 70.01%, Train_loss: 0.570427, Val_accuracy: 64.33%, val_loss: 0.645340\n",
      "Epoch 9: Train_accuracy: 70.85%, Train_loss: 0.557347, Val_accuracy: 65.89%, val_loss: 0.618874\n",
      "Epoch 10: Train_accuracy: 72.37%, Train_loss: 0.542029, Val_accuracy: 64.90%, val_loss: 0.629111\n",
      "Epoch 11: Train_accuracy: 73.74%, Train_loss: 0.524698, Val_accuracy: 65.47%, val_loss: 0.643575\n",
      "Epoch 12: Train_accuracy: 74.40%, Train_loss: 0.517498, Val_accuracy: 66.10%, val_loss: 0.611578\n",
      "Epoch 13: Train_accuracy: 74.84%, Train_loss: 0.507998, Val_accuracy: 67.34%, val_loss: 0.646423\n",
      "Epoch 14: Train_accuracy: 75.87%, Train_loss: 0.490077, Val_accuracy: 67.34%, val_loss: 0.609052\n",
      "Epoch 15: Train_accuracy: 76.67%, Train_loss: 0.478031, Val_accuracy: 67.50%, val_loss: 0.619582\n",
      "Epoch 16: Train_accuracy: 78.03%, Train_loss: 0.458673, Val_accuracy: 69.21%, val_loss: 0.602357\n",
      "Epoch 17: Train_accuracy: 79.43%, Train_loss: 0.443176, Val_accuracy: 68.79%, val_loss: 0.655627\n",
      "Epoch 18: Train_accuracy: 79.38%, Train_loss: 0.433123, Val_accuracy: 71.18%, val_loss: 0.585396\n",
      "Epoch 19: Train_accuracy: 80.16%, Train_loss: 0.428656, Val_accuracy: 69.73%, val_loss: 0.615048\n",
      "Epoch 20: Train_accuracy: 80.48%, Train_loss: 0.418768, Val_accuracy: 69.73%, val_loss: 0.618136\n",
      "Epoch 21: Train_accuracy: 81.45%, Train_loss: 0.409423, Val_accuracy: 69.52%, val_loss: 0.614873\n",
      "Batch size 128, Fold 4, Epoch stopped at 21 with validation loss: 0.6149 and validation accuracy: 0.6952\n",
      "\n",
      "------ Fold: 5 ------\n",
      "Epoch 1: Train_accuracy: 54.15%, Train_loss: 0.686192, Val_accuracy: 56.97%, val_loss: 0.677723\n",
      "Epoch 2: Train_accuracy: 58.13%, Train_loss: 0.671615, Val_accuracy: 56.51%, val_loss: 0.676525\n",
      "Epoch 3: Train_accuracy: 60.65%, Train_loss: 0.656533, Val_accuracy: 59.15%, val_loss: 0.675924\n",
      "Epoch 4: Train_accuracy: 62.61%, Train_loss: 0.645378, Val_accuracy: 61.59%, val_loss: 0.652315\n",
      "Epoch 5: Train_accuracy: 64.27%, Train_loss: 0.633760, Val_accuracy: 61.79%, val_loss: 0.649398\n",
      "Epoch 6: Train_accuracy: 66.29%, Train_loss: 0.611712, Val_accuracy: 62.88%, val_loss: 0.656493\n",
      "Epoch 7: Train_accuracy: 66.67%, Train_loss: 0.604093, Val_accuracy: 62.83%, val_loss: 0.643563\n",
      "Epoch 8: Train_accuracy: 68.82%, Train_loss: 0.582212, Val_accuracy: 65.47%, val_loss: 0.630858\n",
      "Epoch 9: Train_accuracy: 70.22%, Train_loss: 0.568462, Val_accuracy: 62.67%, val_loss: 0.631644\n",
      "Epoch 10: Train_accuracy: 71.09%, Train_loss: 0.554142, Val_accuracy: 66.93%, val_loss: 0.607628\n",
      "Epoch 11: Train_accuracy: 73.24%, Train_loss: 0.535470, Val_accuracy: 66.87%, val_loss: 0.615072\n",
      "Epoch 12: Train_accuracy: 73.03%, Train_loss: 0.522358, Val_accuracy: 66.25%, val_loss: 0.623947\n",
      "Epoch 13: Train_accuracy: 73.38%, Train_loss: 0.522772, Val_accuracy: 67.29%, val_loss: 0.599836\n",
      "Epoch 14: Train_accuracy: 76.18%, Train_loss: 0.498226, Val_accuracy: 67.91%, val_loss: 0.597733\n",
      "Epoch 15: Train_accuracy: 76.45%, Train_loss: 0.485974, Val_accuracy: 69.57%, val_loss: 0.593083\n",
      "Epoch 16: Train_accuracy: 77.11%, Train_loss: 0.472756, Val_accuracy: 66.93%, val_loss: 0.631242\n",
      "Epoch 17: Train_accuracy: 77.64%, Train_loss: 0.469626, Val_accuracy: 69.93%, val_loss: 0.606606\n",
      "Epoch 18: Train_accuracy: 78.46%, Train_loss: 0.455293, Val_accuracy: 68.95%, val_loss: 0.600993\n",
      "Batch size 128, Fold 5, Epoch stopped at 18 with validation loss: 0.6010 and validation accuracy: 0.6895\n",
      "\n",
      "--------------------- Batch Size: 256 ---------------------\n",
      "------ Fold: 1 ------\n",
      "Epoch 1: Train_accuracy: 54.25%, Train_loss: 0.686930, Val_accuracy: 58.37%, val_loss: 0.678905\n",
      "Epoch 2: Train_accuracy: 57.21%, Train_loss: 0.677239, Val_accuracy: 59.46%, val_loss: 0.665962\n",
      "Epoch 3: Train_accuracy: 59.20%, Train_loss: 0.664737, Val_accuracy: 62.93%, val_loss: 0.652822\n",
      "Epoch 4: Train_accuracy: 60.73%, Train_loss: 0.654269, Val_accuracy: 62.00%, val_loss: 0.651198\n",
      "Epoch 5: Train_accuracy: 62.10%, Train_loss: 0.647750, Val_accuracy: 62.73%, val_loss: 0.637228\n",
      "Epoch 6: Train_accuracy: 64.31%, Train_loss: 0.626429, Val_accuracy: 63.56%, val_loss: 0.646118\n",
      "Epoch 7: Train_accuracy: 65.28%, Train_loss: 0.621777, Val_accuracy: 64.59%, val_loss: 0.620069\n",
      "Epoch 8: Train_accuracy: 67.25%, Train_loss: 0.605033, Val_accuracy: 63.97%, val_loss: 0.630205\n",
      "Epoch 9: Train_accuracy: 68.31%, Train_loss: 0.591464, Val_accuracy: 65.79%, val_loss: 0.625020\n",
      "Epoch 10: Train_accuracy: 68.42%, Train_loss: 0.584689, Val_accuracy: 66.72%, val_loss: 0.611644\n",
      "Epoch 11: Train_accuracy: 70.01%, Train_loss: 0.568017, Val_accuracy: 66.61%, val_loss: 0.610622\n",
      "Epoch 12: Train_accuracy: 70.74%, Train_loss: 0.555656, Val_accuracy: 68.12%, val_loss: 0.591154\n",
      "Epoch 13: Train_accuracy: 71.72%, Train_loss: 0.549344, Val_accuracy: 69.98%, val_loss: 0.577323\n",
      "Epoch 14: Train_accuracy: 72.90%, Train_loss: 0.532694, Val_accuracy: 67.44%, val_loss: 0.592804\n",
      "Epoch 15: Train_accuracy: 73.87%, Train_loss: 0.519478, Val_accuracy: 69.36%, val_loss: 0.580002\n",
      "Epoch 16: Train_accuracy: 74.79%, Train_loss: 0.509884, Val_accuracy: 69.52%, val_loss: 0.575976\n",
      "Epoch 17: Train_accuracy: 76.75%, Train_loss: 0.488764, Val_accuracy: 68.48%, val_loss: 0.584927\n",
      "Epoch 18: Train_accuracy: 76.39%, Train_loss: 0.488723, Val_accuracy: 70.40%, val_loss: 0.571613\n",
      "Epoch 19: Train_accuracy: 77.51%, Train_loss: 0.480099, Val_accuracy: 69.78%, val_loss: 0.574341\n",
      "Epoch 20: Train_accuracy: 78.15%, Train_loss: 0.472902, Val_accuracy: 70.87%, val_loss: 0.557576\n",
      "Epoch 21: Train_accuracy: 77.73%, Train_loss: 0.456735, Val_accuracy: 71.90%, val_loss: 0.555548\n",
      "Epoch 22: Train_accuracy: 78.97%, Train_loss: 0.455352, Val_accuracy: 72.01%, val_loss: 0.545592\n",
      "Epoch 23: Train_accuracy: 78.75%, Train_loss: 0.449681, Val_accuracy: 73.46%, val_loss: 0.557473\n",
      "Epoch 24: Train_accuracy: 80.11%, Train_loss: 0.438610, Val_accuracy: 71.90%, val_loss: 0.556448\n",
      "Epoch 25: Train_accuracy: 80.27%, Train_loss: 0.424068, Val_accuracy: 73.15%, val_loss: 0.558021\n",
      "Batch size 256, Fold 1, Epoch stopped at 25 with validation loss: 0.5580 and validation accuracy: 0.7315\n",
      "\n",
      "------ Fold: 2 ------\n",
      "Epoch 1: Train_accuracy: 54.56%, Train_loss: 0.685064, Val_accuracy: 55.62%, val_loss: 0.684716\n",
      "Epoch 2: Train_accuracy: 58.29%, Train_loss: 0.673364, Val_accuracy: 57.02%, val_loss: 0.680065\n",
      "Epoch 3: Train_accuracy: 60.58%, Train_loss: 0.662523, Val_accuracy: 57.85%, val_loss: 0.672894\n",
      "Epoch 4: Train_accuracy: 61.86%, Train_loss: 0.652015, Val_accuracy: 59.31%, val_loss: 0.663278\n",
      "Epoch 5: Train_accuracy: 62.62%, Train_loss: 0.641891, Val_accuracy: 60.71%, val_loss: 0.655982\n",
      "Epoch 6: Train_accuracy: 64.31%, Train_loss: 0.627261, Val_accuracy: 61.64%, val_loss: 0.647028\n",
      "Epoch 7: Train_accuracy: 65.89%, Train_loss: 0.612891, Val_accuracy: 62.52%, val_loss: 0.650089\n",
      "Epoch 8: Train_accuracy: 66.86%, Train_loss: 0.606625, Val_accuracy: 63.45%, val_loss: 0.639616\n",
      "Epoch 9: Train_accuracy: 68.01%, Train_loss: 0.591779, Val_accuracy: 62.78%, val_loss: 0.652294\n",
      "Epoch 10: Train_accuracy: 68.64%, Train_loss: 0.579993, Val_accuracy: 63.61%, val_loss: 0.628378\n",
      "Epoch 11: Train_accuracy: 70.00%, Train_loss: 0.565947, Val_accuracy: 64.28%, val_loss: 0.636397\n",
      "Epoch 12: Train_accuracy: 70.84%, Train_loss: 0.565353, Val_accuracy: 65.22%, val_loss: 0.622658\n",
      "Epoch 13: Train_accuracy: 72.28%, Train_loss: 0.540414, Val_accuracy: 66.46%, val_loss: 0.625801\n",
      "Epoch 14: Train_accuracy: 73.28%, Train_loss: 0.531206, Val_accuracy: 67.65%, val_loss: 0.616104\n",
      "Epoch 15: Train_accuracy: 73.94%, Train_loss: 0.519338, Val_accuracy: 67.50%, val_loss: 0.629848\n",
      "Epoch 16: Train_accuracy: 74.51%, Train_loss: 0.510393, Val_accuracy: 66.77%, val_loss: 0.616220\n",
      "Epoch 17: Train_accuracy: 76.01%, Train_loss: 0.498644, Val_accuracy: 67.24%, val_loss: 0.623508\n",
      "Batch size 256, Fold 2, Epoch stopped at 17 with validation loss: 0.6235 and validation accuracy: 0.6724\n",
      "\n",
      "------ Fold: 3 ------\n",
      "Epoch 1: Train_accuracy: 54.30%, Train_loss: 0.687190, Val_accuracy: 55.57%, val_loss: 0.681604\n",
      "Epoch 2: Train_accuracy: 58.45%, Train_loss: 0.672733, Val_accuracy: 57.28%, val_loss: 0.674943\n",
      "Epoch 3: Train_accuracy: 60.58%, Train_loss: 0.659817, Val_accuracy: 59.51%, val_loss: 0.669296\n",
      "Epoch 4: Train_accuracy: 63.10%, Train_loss: 0.644889, Val_accuracy: 60.65%, val_loss: 0.654549\n",
      "Epoch 5: Train_accuracy: 64.46%, Train_loss: 0.629029, Val_accuracy: 60.13%, val_loss: 0.683964\n",
      "Epoch 6: Train_accuracy: 65.25%, Train_loss: 0.617304, Val_accuracy: 61.53%, val_loss: 0.659356\n",
      "Epoch 7: Train_accuracy: 67.28%, Train_loss: 0.610505, Val_accuracy: 61.74%, val_loss: 0.652551\n",
      "Epoch 8: Train_accuracy: 68.25%, Train_loss: 0.594210, Val_accuracy: 64.80%, val_loss: 0.644627\n",
      "Epoch 9: Train_accuracy: 69.15%, Train_loss: 0.580052, Val_accuracy: 62.21%, val_loss: 0.658975\n",
      "Epoch 10: Train_accuracy: 69.60%, Train_loss: 0.575411, Val_accuracy: 63.87%, val_loss: 0.632945\n",
      "Epoch 11: Train_accuracy: 71.19%, Train_loss: 0.559754, Val_accuracy: 65.53%, val_loss: 0.625778\n",
      "Epoch 12: Train_accuracy: 72.08%, Train_loss: 0.547184, Val_accuracy: 66.10%, val_loss: 0.628202\n",
      "Epoch 13: Train_accuracy: 73.30%, Train_loss: 0.530788, Val_accuracy: 65.47%, val_loss: 0.640081\n",
      "Epoch 14: Train_accuracy: 73.22%, Train_loss: 0.529441, Val_accuracy: 66.72%, val_loss: 0.610660\n",
      "Epoch 15: Train_accuracy: 73.90%, Train_loss: 0.519979, Val_accuracy: 68.38%, val_loss: 0.601999\n",
      "Epoch 16: Train_accuracy: 75.74%, Train_loss: 0.502939, Val_accuracy: 66.93%, val_loss: 0.631964\n",
      "Epoch 17: Train_accuracy: 75.56%, Train_loss: 0.503026, Val_accuracy: 67.65%, val_loss: 0.629085\n",
      "Epoch 18: Train_accuracy: 75.98%, Train_loss: 0.494404, Val_accuracy: 69.21%, val_loss: 0.602086\n",
      "Batch size 256, Fold 3, Epoch stopped at 18 with validation loss: 0.6021 and validation accuracy: 0.6921\n",
      "\n",
      "------ Fold: 4 ------\n",
      "Epoch 1: Train_accuracy: 54.64%, Train_loss: 0.687069, Val_accuracy: 57.54%, val_loss: 0.680725\n",
      "Epoch 2: Train_accuracy: 58.42%, Train_loss: 0.670891, Val_accuracy: 59.82%, val_loss: 0.668213\n",
      "Epoch 3: Train_accuracy: 60.01%, Train_loss: 0.659899, Val_accuracy: 60.13%, val_loss: 0.664637\n",
      "Epoch 4: Train_accuracy: 61.91%, Train_loss: 0.650109, Val_accuracy: 59.88%, val_loss: 0.663336\n",
      "Epoch 5: Train_accuracy: 63.62%, Train_loss: 0.636814, Val_accuracy: 60.39%, val_loss: 0.660722\n",
      "Epoch 6: Train_accuracy: 64.71%, Train_loss: 0.625342, Val_accuracy: 62.73%, val_loss: 0.644919\n",
      "Epoch 7: Train_accuracy: 66.47%, Train_loss: 0.614479, Val_accuracy: 61.69%, val_loss: 0.653550\n",
      "Epoch 8: Train_accuracy: 68.26%, Train_loss: 0.593485, Val_accuracy: 61.90%, val_loss: 0.649278\n",
      "Epoch 9: Train_accuracy: 69.26%, Train_loss: 0.579516, Val_accuracy: 63.87%, val_loss: 0.633160\n",
      "Epoch 10: Train_accuracy: 69.32%, Train_loss: 0.569956, Val_accuracy: 64.75%, val_loss: 0.626285\n",
      "Epoch 11: Train_accuracy: 71.46%, Train_loss: 0.559377, Val_accuracy: 65.11%, val_loss: 0.634081\n",
      "Epoch 12: Train_accuracy: 72.42%, Train_loss: 0.550110, Val_accuracy: 63.50%, val_loss: 0.640672\n",
      "Epoch 13: Train_accuracy: 72.34%, Train_loss: 0.536014, Val_accuracy: 64.49%, val_loss: 0.631184\n",
      "Batch size 256, Fold 4, Epoch stopped at 13 with validation loss: 0.6312 and validation accuracy: 0.6449\n",
      "\n",
      "------ Fold: 5 ------\n",
      "Epoch 1: Train_accuracy: 53.97%, Train_loss: 0.687107, Val_accuracy: 58.22%, val_loss: 0.679911\n",
      "Epoch 2: Train_accuracy: 57.41%, Train_loss: 0.675239, Val_accuracy: 58.89%, val_loss: 0.673672\n",
      "Epoch 3: Train_accuracy: 60.58%, Train_loss: 0.659750, Val_accuracy: 58.53%, val_loss: 0.670247\n",
      "Epoch 4: Train_accuracy: 61.87%, Train_loss: 0.648436, Val_accuracy: 60.03%, val_loss: 0.666115\n",
      "Epoch 5: Train_accuracy: 64.02%, Train_loss: 0.634375, Val_accuracy: 61.38%, val_loss: 0.656973\n",
      "Epoch 6: Train_accuracy: 64.74%, Train_loss: 0.627140, Val_accuracy: 60.60%, val_loss: 0.655998\n",
      "Epoch 7: Train_accuracy: 65.44%, Train_loss: 0.611699, Val_accuracy: 63.09%, val_loss: 0.651801\n",
      "Epoch 8: Train_accuracy: 67.07%, Train_loss: 0.605559, Val_accuracy: 63.92%, val_loss: 0.638056\n",
      "Epoch 9: Train_accuracy: 67.42%, Train_loss: 0.595576, Val_accuracy: 64.07%, val_loss: 0.638156\n",
      "Epoch 10: Train_accuracy: 68.35%, Train_loss: 0.587734, Val_accuracy: 63.09%, val_loss: 0.640048\n",
      "Epoch 11: Train_accuracy: 69.73%, Train_loss: 0.572280, Val_accuracy: 64.59%, val_loss: 0.646479\n",
      "Batch size 256, Fold 5, Epoch stopped at 11 with validation loss: 0.6465 and validation accuracy: 0.6459\n",
      "\n",
      "--------------------- Batch Size: 512 ---------------------\n",
      "------ Fold: 1 ------\n",
      "Epoch 1: Train_accuracy: 53.98%, Train_loss: 0.690140, Val_accuracy: 57.34%, val_loss: 0.683828\n",
      "Epoch 2: Train_accuracy: 56.97%, Train_loss: 0.680287, Val_accuracy: 58.58%, val_loss: 0.674013\n",
      "Epoch 3: Train_accuracy: 58.23%, Train_loss: 0.674022, Val_accuracy: 60.19%, val_loss: 0.667192\n",
      "Epoch 4: Train_accuracy: 59.32%, Train_loss: 0.666115, Val_accuracy: 60.91%, val_loss: 0.659474\n",
      "Epoch 5: Train_accuracy: 60.94%, Train_loss: 0.657563, Val_accuracy: 61.12%, val_loss: 0.654467\n",
      "Epoch 6: Train_accuracy: 61.39%, Train_loss: 0.651703, Val_accuracy: 62.16%, val_loss: 0.647645\n",
      "Epoch 7: Train_accuracy: 61.83%, Train_loss: 0.642684, Val_accuracy: 62.05%, val_loss: 0.650106\n",
      "Epoch 8: Train_accuracy: 62.93%, Train_loss: 0.638248, Val_accuracy: 63.66%, val_loss: 0.634546\n",
      "Epoch 9: Train_accuracy: 64.49%, Train_loss: 0.627367, Val_accuracy: 63.56%, val_loss: 0.635077\n",
      "Epoch 10: Train_accuracy: 65.12%, Train_loss: 0.622268, Val_accuracy: 64.59%, val_loss: 0.631331\n",
      "Epoch 11: Train_accuracy: 66.99%, Train_loss: 0.609562, Val_accuracy: 65.58%, val_loss: 0.626884\n",
      "Epoch 12: Train_accuracy: 67.25%, Train_loss: 0.606793, Val_accuracy: 65.01%, val_loss: 0.632616\n",
      "Epoch 13: Train_accuracy: 67.65%, Train_loss: 0.593758, Val_accuracy: 65.73%, val_loss: 0.622180\n",
      "Epoch 14: Train_accuracy: 68.71%, Train_loss: 0.586409, Val_accuracy: 66.67%, val_loss: 0.616368\n",
      "Epoch 15: Train_accuracy: 68.92%, Train_loss: 0.585971, Val_accuracy: 66.51%, val_loss: 0.615526\n",
      "Epoch 16: Train_accuracy: 70.04%, Train_loss: 0.570899, Val_accuracy: 66.56%, val_loss: 0.613642\n",
      "Epoch 17: Train_accuracy: 69.96%, Train_loss: 0.563955, Val_accuracy: 66.87%, val_loss: 0.603792\n",
      "Epoch 18: Train_accuracy: 70.81%, Train_loss: 0.565946, Val_accuracy: 66.67%, val_loss: 0.608449\n",
      "Epoch 19: Train_accuracy: 71.79%, Train_loss: 0.550535, Val_accuracy: 67.86%, val_loss: 0.608020\n",
      "Epoch 20: Train_accuracy: 72.52%, Train_loss: 0.541417, Val_accuracy: 66.72%, val_loss: 0.607912\n",
      "Batch size 512, Fold 1, Epoch stopped at 20 with validation loss: 0.6079 and validation accuracy: 0.6672\n",
      "\n",
      "------ Fold: 2 ------\n",
      "Epoch 1: Train_accuracy: 54.12%, Train_loss: 0.688252, Val_accuracy: 54.59%, val_loss: 0.688273\n",
      "Epoch 2: Train_accuracy: 58.14%, Train_loss: 0.679464, Val_accuracy: 56.77%, val_loss: 0.679860\n",
      "Epoch 3: Train_accuracy: 59.38%, Train_loss: 0.670506, Val_accuracy: 56.14%, val_loss: 0.676974\n",
      "Epoch 4: Train_accuracy: 61.16%, Train_loss: 0.659707, Val_accuracy: 57.49%, val_loss: 0.673242\n",
      "Epoch 5: Train_accuracy: 62.29%, Train_loss: 0.648005, Val_accuracy: 60.76%, val_loss: 0.663824\n",
      "Epoch 6: Train_accuracy: 63.19%, Train_loss: 0.639979, Val_accuracy: 59.93%, val_loss: 0.658050\n",
      "Epoch 7: Train_accuracy: 64.06%, Train_loss: 0.638101, Val_accuracy: 60.39%, val_loss: 0.667795\n",
      "Epoch 8: Train_accuracy: 64.39%, Train_loss: 0.630668, Val_accuracy: 61.79%, val_loss: 0.654439\n",
      "Epoch 9: Train_accuracy: 65.69%, Train_loss: 0.615141, Val_accuracy: 61.48%, val_loss: 0.657416\n",
      "Epoch 10: Train_accuracy: 66.67%, Train_loss: 0.613988, Val_accuracy: 61.22%, val_loss: 0.653724\n",
      "Epoch 11: Train_accuracy: 66.81%, Train_loss: 0.598159, Val_accuracy: 62.36%, val_loss: 0.650544\n",
      "Epoch 12: Train_accuracy: 68.36%, Train_loss: 0.592545, Val_accuracy: 62.83%, val_loss: 0.637949\n",
      "Epoch 13: Train_accuracy: 68.66%, Train_loss: 0.583834, Val_accuracy: 62.36%, val_loss: 0.662493\n",
      "Epoch 14: Train_accuracy: 69.23%, Train_loss: 0.578742, Val_accuracy: 64.75%, val_loss: 0.631673\n",
      "Epoch 15: Train_accuracy: 70.54%, Train_loss: 0.567487, Val_accuracy: 63.82%, val_loss: 0.643089\n",
      "Epoch 16: Train_accuracy: 71.40%, Train_loss: 0.558368, Val_accuracy: 65.68%, val_loss: 0.626164\n",
      "Epoch 17: Train_accuracy: 70.85%, Train_loss: 0.566669, Val_accuracy: 65.11%, val_loss: 0.630455\n",
      "Epoch 18: Train_accuracy: 71.60%, Train_loss: 0.543599, Val_accuracy: 66.04%, val_loss: 0.627219\n",
      "Epoch 19: Train_accuracy: 72.60%, Train_loss: 0.554154, Val_accuracy: 66.36%, val_loss: 0.617085\n",
      "Epoch 20: Train_accuracy: 72.85%, Train_loss: 0.532030, Val_accuracy: 67.08%, val_loss: 0.620314\n",
      "Epoch 21: Train_accuracy: 74.29%, Train_loss: 0.530540, Val_accuracy: 65.37%, val_loss: 0.624565\n",
      "Epoch 22: Train_accuracy: 73.77%, Train_loss: 0.517433, Val_accuracy: 66.36%, val_loss: 0.615958\n",
      "Epoch 23: Train_accuracy: 74.42%, Train_loss: 0.512464, Val_accuracy: 68.58%, val_loss: 0.610707\n",
      "Epoch 24: Train_accuracy: 74.39%, Train_loss: 0.517316, Val_accuracy: 67.44%, val_loss: 0.611106\n",
      "Epoch 25: Train_accuracy: 75.52%, Train_loss: 0.501145, Val_accuracy: 66.87%, val_loss: 0.616000\n",
      "Epoch 26: Train_accuracy: 76.02%, Train_loss: 0.489857, Val_accuracy: 68.43%, val_loss: 0.613195\n",
      "Batch size 512, Fold 2, Epoch stopped at 26 with validation loss: 0.6132 and validation accuracy: 0.6843\n",
      "\n",
      "------ Fold: 3 ------\n",
      "Epoch 1: Train_accuracy: 52.66%, Train_loss: 0.691265, Val_accuracy: 57.08%, val_loss: 0.683079\n",
      "Epoch 2: Train_accuracy: 57.81%, Train_loss: 0.678978, Val_accuracy: 57.34%, val_loss: 0.678804\n",
      "Epoch 3: Train_accuracy: 59.02%, Train_loss: 0.666436, Val_accuracy: 56.45%, val_loss: 0.674884\n",
      "Epoch 4: Train_accuracy: 60.29%, Train_loss: 0.659475, Val_accuracy: 59.62%, val_loss: 0.663524\n",
      "Epoch 5: Train_accuracy: 62.27%, Train_loss: 0.654912, Val_accuracy: 59.41%, val_loss: 0.665560\n",
      "Epoch 6: Train_accuracy: 62.23%, Train_loss: 0.652071, Val_accuracy: 60.29%, val_loss: 0.661553\n",
      "Epoch 7: Train_accuracy: 63.50%, Train_loss: 0.638539, Val_accuracy: 58.94%, val_loss: 0.670085\n",
      "Epoch 8: Train_accuracy: 64.10%, Train_loss: 0.628519, Val_accuracy: 60.96%, val_loss: 0.666380\n",
      "Epoch 9: Train_accuracy: 64.92%, Train_loss: 0.626186, Val_accuracy: 62.31%, val_loss: 0.650347\n",
      "Epoch 10: Train_accuracy: 66.11%, Train_loss: 0.607600, Val_accuracy: 62.00%, val_loss: 0.658748\n",
      "Epoch 11: Train_accuracy: 66.80%, Train_loss: 0.597302, Val_accuracy: 62.93%, val_loss: 0.651256\n",
      "Epoch 12: Train_accuracy: 67.33%, Train_loss: 0.598577, Val_accuracy: 63.71%, val_loss: 0.643352\n",
      "Epoch 13: Train_accuracy: 68.52%, Train_loss: 0.583297, Val_accuracy: 63.56%, val_loss: 0.648481\n",
      "Epoch 14: Train_accuracy: 69.82%, Train_loss: 0.575201, Val_accuracy: 64.39%, val_loss: 0.647282\n",
      "Epoch 15: Train_accuracy: 69.73%, Train_loss: 0.569749, Val_accuracy: 64.28%, val_loss: 0.645895\n",
      "Batch size 512, Fold 3, Epoch stopped at 15 with validation loss: 0.6459 and validation accuracy: 0.6428\n",
      "\n",
      "------ Fold: 4 ------\n",
      "Epoch 1: Train_accuracy: 54.29%, Train_loss: 0.688438, Val_accuracy: 58.01%, val_loss: 0.682473\n",
      "Epoch 2: Train_accuracy: 56.65%, Train_loss: 0.678495, Val_accuracy: 58.01%, val_loss: 0.677882\n",
      "Epoch 3: Train_accuracy: 58.49%, Train_loss: 0.669484, Val_accuracy: 59.10%, val_loss: 0.675113\n",
      "Epoch 4: Train_accuracy: 59.85%, Train_loss: 0.664466, Val_accuracy: 58.99%, val_loss: 0.672097\n",
      "Epoch 5: Train_accuracy: 61.31%, Train_loss: 0.656241, Val_accuracy: 60.34%, val_loss: 0.667483\n",
      "Epoch 6: Train_accuracy: 62.21%, Train_loss: 0.648451, Val_accuracy: 60.03%, val_loss: 0.660337\n",
      "Epoch 7: Train_accuracy: 63.71%, Train_loss: 0.635249, Val_accuracy: 61.43%, val_loss: 0.654072\n",
      "Epoch 8: Train_accuracy: 63.93%, Train_loss: 0.634699, Val_accuracy: 59.93%, val_loss: 0.659800\n",
      "Epoch 9: Train_accuracy: 65.63%, Train_loss: 0.629804, Val_accuracy: 61.43%, val_loss: 0.653391\n",
      "Epoch 10: Train_accuracy: 66.03%, Train_loss: 0.614276, Val_accuracy: 60.96%, val_loss: 0.651039\n",
      "Epoch 11: Train_accuracy: 66.07%, Train_loss: 0.610885, Val_accuracy: 61.74%, val_loss: 0.649943\n",
      "Epoch 12: Train_accuracy: 67.68%, Train_loss: 0.598547, Val_accuracy: 62.47%, val_loss: 0.642466\n",
      "Epoch 13: Train_accuracy: 68.82%, Train_loss: 0.591827, Val_accuracy: 61.95%, val_loss: 0.640258\n",
      "Epoch 14: Train_accuracy: 69.93%, Train_loss: 0.580307, Val_accuracy: 64.33%, val_loss: 0.627130\n",
      "Epoch 15: Train_accuracy: 69.92%, Train_loss: 0.575285, Val_accuracy: 63.71%, val_loss: 0.643631\n",
      "Epoch 16: Train_accuracy: 70.55%, Train_loss: 0.568755, Val_accuracy: 62.57%, val_loss: 0.642142\n",
      "Epoch 17: Train_accuracy: 71.57%, Train_loss: 0.558129, Val_accuracy: 64.96%, val_loss: 0.628691\n",
      "Batch size 512, Fold 4, Epoch stopped at 17 with validation loss: 0.6287 and validation accuracy: 0.6496\n",
      "\n",
      "------ Fold: 5 ------\n",
      "Epoch 1: Train_accuracy: 53.86%, Train_loss: 0.687208, Val_accuracy: 55.62%, val_loss: 0.683683\n",
      "Epoch 2: Train_accuracy: 56.61%, Train_loss: 0.680462, Val_accuracy: 56.30%, val_loss: 0.683405\n",
      "Epoch 3: Train_accuracy: 58.68%, Train_loss: 0.669732, Val_accuracy: 58.84%, val_loss: 0.676154\n",
      "Epoch 4: Train_accuracy: 60.03%, Train_loss: 0.659244, Val_accuracy: 58.68%, val_loss: 0.667414\n",
      "Epoch 5: Train_accuracy: 60.98%, Train_loss: 0.655122, Val_accuracy: 58.58%, val_loss: 0.671142\n",
      "Epoch 6: Train_accuracy: 62.42%, Train_loss: 0.641873, Val_accuracy: 59.56%, val_loss: 0.663784\n",
      "Epoch 7: Train_accuracy: 63.19%, Train_loss: 0.633777, Val_accuracy: 59.41%, val_loss: 0.661876\n",
      "Epoch 8: Train_accuracy: 63.75%, Train_loss: 0.630747, Val_accuracy: 60.91%, val_loss: 0.661208\n",
      "Epoch 9: Train_accuracy: 65.03%, Train_loss: 0.626698, Val_accuracy: 61.79%, val_loss: 0.653136\n",
      "Epoch 10: Train_accuracy: 65.34%, Train_loss: 0.610192, Val_accuracy: 63.82%, val_loss: 0.642694\n",
      "Epoch 11: Train_accuracy: 66.63%, Train_loss: 0.606186, Val_accuracy: 62.62%, val_loss: 0.646453\n",
      "Epoch 12: Train_accuracy: 67.02%, Train_loss: 0.596201, Val_accuracy: 63.97%, val_loss: 0.642264\n",
      "Epoch 13: Train_accuracy: 68.08%, Train_loss: 0.596494, Val_accuracy: 64.54%, val_loss: 0.630008\n",
      "Epoch 14: Train_accuracy: 69.66%, Train_loss: 0.576151, Val_accuracy: 64.64%, val_loss: 0.636502\n",
      "Epoch 15: Train_accuracy: 69.65%, Train_loss: 0.575957, Val_accuracy: 64.23%, val_loss: 0.638631\n",
      "Epoch 16: Train_accuracy: 70.67%, Train_loss: 0.559693, Val_accuracy: 62.99%, val_loss: 0.641896\n",
      "Batch size 512, Fold 5, Epoch stopped at 16 with validation loss: 0.6419 and validation accuracy: 0.6299\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from common_utils import EarlyStopper\n",
    "\n",
    "def find_optimal_hyperparameter(X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict, batch_sizes, hyperparameter_name):\n",
    "    train_loaders_dict, val_loaders_dict = get_train_val_loaders_dict(X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict, batch_sizes)\n",
    "    \n",
    "    no_features = 77\n",
    "    no_hidden = 128\n",
    "    no_labels = 1\n",
    "\n",
    "    no_folds = 5\n",
    "    lr = 0.001\n",
    "    epochs = 100\n",
    "    patience = 3\n",
    "\n",
    "    # Keep the mean of the from the last epoch from ALL fold from each BATCH SIZE\n",
    "    cv_correct  = {}  \n",
    "    cv_time = {}\n",
    "    cv_loss = {}\n",
    "\n",
    "    for batch_size in batch_sizes:\n",
    "        print(f'--------------------- Batch Size: {batch_size} ---------------------')\n",
    "\n",
    "        batch_size_accuracies = []\n",
    "        batch_size_times = []\n",
    "        batch_size_losses = []\n",
    "\n",
    "        for fold in range(no_folds):\n",
    "            print(f'------ Fold: {fold + 1} ------')\n",
    "\n",
    "            model = MLP(no_features, no_hidden, no_labels)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "            loss_fn = nn.BCELoss()\n",
    "            early_stopper = EarlyStopper(patience=patience, min_delta=0)\n",
    "\n",
    "            for t in range(epochs):\n",
    "                start_time = time.time()\n",
    "\n",
    "                train_loss, train_correct = train_loop(train_loaders_dict[batch_size][fold], model,loss_fn, optimizer)\n",
    "                val_loss, val_correct = test_loop(val_loaders_dict[batch_size][fold], model, loss_fn)\n",
    "                \n",
    "                print(f\"Epoch {t+1}: Train_accuracy: {(100*train_correct):>0.2f}%, Train_loss: {train_loss:>8f}, Val_accuracy: {(100*val_correct):>0.2f}%, val_loss: {val_loss:>8f}\")\n",
    "\n",
    "                if early_stopper.early_stop(val_loss):\n",
    "                    end_time = time.time() - start_time\n",
    "                    \n",
    "                    batch_size_times.append(end_time) \n",
    "                    batch_size_accuracies.append(val_correct)  \n",
    "                    batch_size_losses.append(val_loss) \n",
    "\n",
    "                    print(f\"Batch size {batch_size}, Fold {fold + 1}, Epoch stopped at {t + 1} with validation loss: {val_loss:.4f} and validation accuracy: {val_correct:.4f}\")\n",
    "                    print()\n",
    "                    break\n",
    "        \n",
    "        cv_correct[batch_size] = np.mean(batch_size_accuracies)\n",
    "        cv_time[batch_size] = np.mean(batch_size_times)\n",
    "        cv_loss[batch_size] = np.mean(batch_size_losses)\n",
    "    \n",
    "    return cv_correct, cv_time\n",
    "\n",
    "\n",
    "batch_sizes = [64, 128, 256, 512]\n",
    "cross_validation_accuracies, cross_validation_times = find_optimal_hyperparameter(X_train_scaled_dict, X_val_scaled_dict, y_train_dict, y_val_dict, batch_sizes, 'batch_size')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Plot scatterplot of mean cross validation accuracies for the different batch sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{64: 0.69134265, 128: 0.6708139, 256: 0.6773458, 512: 0.6547434}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(cross_validation_accuracies.keys(), cross_validation_accuracies.values(), color='blue')\n",
    "plt.title('Mean Cross-Validation Accuracies for Different Batch Sizes')\n",
    "plt.xlabel('Batch Size')\n",
    "plt.xticks(ticks=batch_sizes, labels = [str(batch_size) for batch_size in batch_sizes])\n",
    "plt.ylabel('Mean Cross-Validation Accuracy')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.Create a table of time taken to train the network on the last epoch against different batch sizes. Select the optimal batch size and state a reason for your selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{64: 0.3439652442932129,\n",
       " 128: 0.19534702301025392,\n",
       " 256: 0.1374824047088623,\n",
       " 512: 0.10349373817443848}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batch Size</th>\n",
       "      <th>Last Epoch Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>0.343965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128</td>\n",
       "      <td>0.195347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>256</td>\n",
       "      <td>0.137482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>512</td>\n",
       "      <td>0.103494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Batch Size  Last Epoch Time\n",
       "0          64         0.343965\n",
       "1         128         0.195347\n",
       "2         256         0.137482\n",
       "3         512         0.103494"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Batch Size': list(cross_validation_times.keys()),\n",
    "                   'Last Epoch Time': list(cross_validation_times.values())\n",
    "                  })\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "optimal_batch_size = 64\n",
    "reason = \"\"\"\n",
    "# Batch Size Analysis: Trade-off Between Accuracy and Speed\n",
    "\n",
    "- **Larger batch sizes** generally lead to **faster training** due to:\n",
    "  - Improved **parallelism**\n",
    "  - More efficient **matrix operations**\n",
    "  \n",
    "- Data analysis shows that increasing the batch size corresponds to **shorter epoch times**.\n",
    "<br/><br/>\n",
    "\n",
    "- **Batch Size 64**:\n",
    "  - Achieves the **highest accuracy** at **69.13%**\n",
    "  - Computational Time: **0.34 seconds**\n",
    "  \n",
    "- **Batch Size 256**:\n",
    "  - Achieves the **second highest accuracy** of **67.73%** \n",
    "  - Computational Time: **0.14 seconds**\n",
    "\n",
    "A decrease in 1.4% accuracy, led to a a 58% faster computational time\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "- For **smaller datasets** (e.g., 9,645 samples), batch size **64** may be preferable to maximize accuracy. Since our data set is small, we will be choose 64 as our optimal sample\n",
    "- For **larger datasets** (e.g., in the millions), batch size **256** becomes the better choice due to its superior efficiency\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Size Analysis: Trade-off Between Accuracy and Speed\n",
    "\n",
    "- **Larger batch sizes** generally lead to **faster training** due to:\n",
    "  - Improved **parallelism**\n",
    "  - More efficient **matrix operations**\n",
    "  \n",
    "- Data analysis shows that increasing the batch size corresponds to **shorter epoch times**.\n",
    "<br/><br/>\n",
    "\n",
    "- **Batch Size 64**:\n",
    "  - Achieves the **highest accuracy** at **69.13%**\n",
    "  - Computational Time: **0.34 seconds**\n",
    "  \n",
    "- **Batch Size 256**:\n",
    "  - Achieves the **second highest accuracy** of **67.73%** \n",
    "  - Computational Time: **0.14 seconds**\n",
    "\n",
    "A decrease in 1.4% accuracy, led to a a 58% faster computational time\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "- For **smaller datasets** (e.g., 9,645 samples), batch size **64** may be preferable to maximize accuracy. Since our data set is small, we will be choose 64 as our optimal sample\n",
    "- For **larger datasets** (e.g., in the millions), batch size **256** becomes the better choice due to its superior efficiency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipynb-dump",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
